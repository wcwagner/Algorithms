{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elements Of Programming Interviews\n",
    "## Hash Tables\n",
    "### Track 9: 13.1, 13.2, 13.3, 13.4, 13.5, 13.7, 13.8, 13.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1 - Partitioning Into Anagrams\n",
    "Anagrams are popular word play puzzles, where by rearranging letters of one set of words, you get another set of words. For example, \"eleven plus two\" is an anagram for \"twelve plus one\".\n",
    "\n",
    "Write a program that takes as input a set of words and returns group of anagrams for those words.\n",
    "\n",
    "For example, if the input is:\n",
    "\n",
    "*\"debitcard\", \"elvis\", \"silent\", \"badcredit\", \"lives\", \"freedom\", \"listen\", \"levis\"*\n",
    "\n",
    "Then there are three groups of anagrams:\n",
    "\n",
    "1. \"debitcard\", \"badcredit\"\n",
    "2. \"elvis\", \"lives\", \"levis\"\n",
    "3. \"silent\", \"listen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_anagrams(words):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HashTable(object):\n",
    "    #simple ht class to solve anagram algorithm below\n",
    "    def __init__(self, hash_function, size=256):\n",
    "        self.hash_function = hash_function\n",
    "        self.buckets = [list() for i in range(size)]\n",
    "        self.size = size\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        hash_value = self.hash_function(key) % self.size\n",
    "        bucket = self.buckets[hash_value]\n",
    "        if bucket:\n",
    "            return bucket\n",
    "        else:\n",
    "            raise KeyError(key)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        hash_value = self.hash_function(key) % self.size\n",
    "        bucket = self.buckets[hash_value]\n",
    "        i = 0\n",
    "        found = False\n",
    "        for stored_value in bucket:\n",
    "            if stored_value == key:\n",
    "                 found = True\n",
    "                 break\n",
    "            i += 1\n",
    "        if not found:\n",
    "            bucket.append(value)\n",
    "            \n",
    "    def get_buckets(self):\n",
    "        ret = []\n",
    "        for bucket in self.buckets:\n",
    "            if len(bucket) >= 2:\n",
    "                ret.append(bucket)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def string_hash(word):\n",
    "    val = 0\n",
    "    for c in word:\n",
    "        val += ord(c)\n",
    "    return val\n",
    "\n",
    "def group_anagrams(words):\n",
    "    ht = HashTable(string_hash)\n",
    "    for word in words:\n",
    "        ht[word] = word\n",
    "    return ht.get_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_anagrams_alt(words):\n",
    "    h = {}\n",
    "    for word in words:\n",
    "        key = \"\".join(sorted(word))\n",
    "        if key in h.keys():\n",
    "            h[key].append(word)\n",
    "        else:\n",
    "            h[key] = [word]\n",
    "    groups = []\n",
    "    for key in h:\n",
    "        if len(h[key]) >= 2:\n",
    "            groups.append(h[key])\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['elvis', 'lives'], ['listen', 'silent'], ['debitcard', 'badcredit']],\n",
       " [['elvis', 'lives'], ['debitcard', 'badcredit'], ['listen', 'silent']])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg = [\"debitcard\", \"elvis\", \"listen\", \"badcredit\", \"lives\", \"silent\"]\n",
    "group_anagrams(arg), group_anagrams_alt(arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2 - Test For Palindromic Permutations\n",
    "Write a program to test whether the letters forming a string can be permuted to form a palindrome. For example, \"edified\" can be permuted to form \"deified\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_for_palindromic_permutation(word):\n",
    "    char_to_freq = {}\n",
    "    for char in word:\n",
    "        if char in char_to_freq.keys():\n",
    "            char_to_freq[char] += 1\n",
    "        else:\n",
    "            char_to_freq[char] = 1\n",
    "    odd_freq_count = 0\n",
    "    for freq in char_to_freq.values():\n",
    "        if freq % 2:\n",
    "            odd_freq_count += 1\n",
    "    return bool(odd_freq_count % 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_palindromic_permutation(\"edified\"), test_for_palindromic_permutation(\"banana\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.3 - Is An Anonymous Letter Constructable\n",
    "You are required to write a method which takes text for an anonymous letter and text for a magazine. Your method is to determine if it is possible to write the anonymous letter using the text from the magazine. The anonymous letter can be written from the magazine if for each character whether the number of times it appears in the anonymous letter is less than or equal to the number of times it appears in the magazine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabet=\"abcdefghijklmnopqrstuvwxyz\"\n",
    "def construct_letter_from_text(letter, text):\n",
    "    \"\"\"\n",
    "    Constructs letter only if text contains enough characters\n",
    "    returns True if able to, False if not\n",
    "    \"\"\"\n",
    "    letter_char_counts = {letter:0 for letter in alphabet }\n",
    "    text_char_counts = {letter:0 for letter in alphabet}\n",
    "    for c in letter:\n",
    "        if c.isalpha():\n",
    "            letter_char_counts[c.lower()] += 1\n",
    "    for c in text:\n",
    "        if c.isalpha():\n",
    "            text_char_counts[c.lower()] += 1\n",
    "    #now make sure that text has enough respective letters to construct\n",
    "    #the anonymous letter\n",
    "    for char, freq in text_char_counts.items():\n",
    "        if freq < letter_char_counts[char]:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this modified algorithm will terminate earlier\n",
    "def construct_letter_from_text(letter, text):\n",
    "    letter_char_freq = {}\n",
    "    for c in letter:\n",
    "        if c in letter_char_freq:\n",
    "            letter_char_freq[c] += 1\n",
    "        else:\n",
    "            letter_char_freq[c] = 1\n",
    "    for c in text:\n",
    "        if not letter_char_freq:\n",
    "            break\n",
    "        if c in letter_char_freq:\n",
    "            letter_char_freq[c] -= 1\n",
    "            if letter_char_freq[c] == 0:\n",
    "                del letter_char_freq[c]\n",
    "    if not letter_char_freq:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(construct_letter_from_text(\"aa b c d e f g\", \"g f e d c b aa\"),\n",
    " construct_letter_from_text(\"aa b c d e f g\", \"a b c d e f g\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.4 - Implement An ISBN Cache\n",
    "Implement a cache for looking up prices of books identified by their ISBN. You should support lookup, insert, update, and remove methods. Use the Least Recenetly Used strategy for eviction policty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "from datetime import datetime\n",
    "import random\n",
    "class ISBNCache():\n",
    "    \n",
    "    def __init__(self, max_size = 5):\n",
    "        self.cache = {}\n",
    "        self.max_size = max_size\n",
    "    def lookup(self, ISBN):\n",
    "        \"\"\"returns the price\"\"\"\n",
    "        if ISBN not in self.cache:\n",
    "            raise KeyError(str(ISBN) + \" not found in cache\")\n",
    "        #update the timestamp to indicate recently used\n",
    "        self.cache[ISBN][1] = datetime.now()\n",
    "        return self.cache[ISBN][0]\n",
    "    \n",
    "    def update(self, ISBN, price):\n",
    "        if ISBN not in self.cache:\n",
    "            raise KeyError(str(ISBN) + \" not found in cache\")\n",
    "        #update the price\n",
    "        self.cache[ISBN] = (price, datetime.now())\n",
    "    \n",
    "    def insert(self, ISBN, price):\n",
    "        if len(self.cache) > 2 * self.max_size:\n",
    "            timestamps = [bucket[1] for ISBN, bucket in self.cache.items()]\n",
    "            median_time = statistics.median(timestamps)\n",
    "            #deleting any ISBN that was last used before the median time\n",
    "            ISBNs_to_delete = []\n",
    "            for ISBN, bucket in self.cache.items():\n",
    "                if bucket[1] < median_time:\n",
    "                    ISBNs_to_delete.append(ISBN)\n",
    "            for ISBN in ISBNs_to_delete:\n",
    "                del self.cache[ISBN]\n",
    "        self.cache[ISBN] = (price, datetime.now())\n",
    "        \n",
    "    def delete(self, ISBN):\n",
    "        if ISBN not in self.cache:\n",
    "            raise KeyError(str(ISBN) + \" not found in cache\")\n",
    "        del self.cache[ISBN]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ic = ISBNCache()\n",
    "for ISBN in range(409234051, 409234063):\n",
    "    ic.insert(ISBN, float(random.randint(5,55)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409234055 (40.0, datetime.datetime(2016, 8, 17, 7, 50, 45, 153163))\n",
      "409234056 (54.0, datetime.datetime(2016, 8, 17, 7, 50, 45, 153094))\n",
      "409234057 (39.0, datetime.datetime(2016, 8, 17, 7, 50, 45, 153103))\n",
      "409234058 (9.0, datetime.datetime(2016, 8, 17, 7, 50, 45, 153112))\n",
      "409234059 (21.0, datetime.datetime(2016, 8, 17, 7, 50, 45, 153120))\n",
      "409234060 (43.0, datetime.datetime(2016, 8, 17, 7, 50, 45, 153128))\n",
      "409234061 (15.0, datetime.datetime(2016, 8, 17, 7, 50, 45, 153136))\n"
     ]
    }
   ],
   "source": [
    "for ISBN, bucket in ic.cache.items():\n",
    "    print(ISBN, bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409234055 (40.0, datetime.datetime(2016, 8, 17, 7, 50, 45, 153163))\n",
      "409234056 (54.0, datetime.datetime(2016, 8, 17, 7, 50, 45, 153094))\n",
      "409234057 (55, datetime.datetime(2016, 8, 17, 7, 50, 45, 358841))\n",
      "409234058 (9.0, datetime.datetime(2016, 8, 17, 7, 50, 45, 153112))\n",
      "409234059 (21.0, datetime.datetime(2016, 8, 17, 7, 50, 45, 153120))\n",
      "409234060 (43.0, datetime.datetime(2016, 8, 17, 7, 50, 45, 153128))\n",
      "409234061 (15.0, datetime.datetime(2016, 8, 17, 7, 50, 45, 153136))\n"
     ]
    }
   ],
   "source": [
    "ic.update(409234057, 55)\n",
    "for ISBN, bucket in ic.cache.items():\n",
    "    print(ISBN, bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409234055 (40.0, datetime.datetime(2016, 8, 17, 7, 50, 45, 153163))\n",
      "409234056 (54.0, datetime.datetime(2016, 8, 17, 7, 50, 45, 153094))\n",
      "409234058 (9.0, datetime.datetime(2016, 8, 17, 7, 50, 45, 153112))\n",
      "409234059 (21.0, datetime.datetime(2016, 8, 17, 7, 50, 45, 153120))\n",
      "409234060 (43.0, datetime.datetime(2016, 8, 17, 7, 50, 45, 153128))\n",
      "409234061 (15.0, datetime.datetime(2016, 8, 17, 7, 50, 45, 153136))\n"
     ]
    }
   ],
   "source": [
    "ic.delete(409234057)\n",
    "for ISBN, bucket in ic.cache.items():\n",
    "    print(ISBN, bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.5 - Compute The LCA, Optimizing For Close Ancestors\n",
    "Design an algorithms for computing the LCA of two nodes in a binary tree. The algorithms time complexity should depend only on the distance from the nodes to the LCA.\n",
    "\n",
    "<img src='Images/traversals.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extremely inefficient but basic method of creating a BT w/ parent attr in nodes\n",
    "class Node():\n",
    "    def __init__(self, data, parent=None, left=None, right=None):\n",
    "        self.data = data\n",
    "        self.parent = parent\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "nodes = {ch : Node(ch) for ch in 'ABCDEFGHI'}\n",
    "nodes['H'].parent = nodes['E'];nodes['I'].parent = nodes['E'] \n",
    "nodes['E'].left = nodes['H']; nodes['E'].right = nodes['I']\n",
    "nodes['D'].parent = nodes['B']; nodes['E'].parent = nodes['B']\n",
    "nodes['B'].left = nodes['D']; nodes['B'].right = nodes['E']\n",
    "nodes['B'].parent = nodes['A']; nodes['C'].parent = nodes['A']\n",
    "nodes['A'].left = nodes['B']; nodes['A'].right = nodes['C']\n",
    "nodes['F'].parent = nodes['C']; nodes['G'].parent = nodes['C']\n",
    "nodes['C'].left = nodes['F']; nodes['C'].right = nodes['G']\n",
    "root = nodes['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lca(node1, node2):\n",
    "    visited_nodes = {}\n",
    "    while node1 and node2:\n",
    "        if node1:\n",
    "            if node1 in visited_nodes:\n",
    "                #LCA\n",
    "                return node1\n",
    "            else:\n",
    "                visited_nodes[node1] = 1\n",
    "            node1 = node1.parent\n",
    "        if node2:\n",
    "            if node2 in visited_nodes:\n",
    "                return node2\n",
    "            else:\n",
    "                visited_nodes[node2] = 1\n",
    "            node2 = node2.parent\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('H', 'A', 'B')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(get_lca(nodes['H'], nodes['H']).data,#H\n",
    " get_lca(nodes['D'], nodes['G']).data,#A\n",
    " get_lca(nodes['D'], nodes['I']).data #B\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.7 - Find The Nearest Repeated Entries In An Array\n",
    "People do not like reading text in which a word is used multiple times in a short paragraph. You are to write a program which helps identify such a problem. Write a program which takes as input an array and finds the distance between a closest pairs of equal entires.\n",
    "\n",
    "For example, if s = [\"All\", \"work\", \"and\", \"no\", \"play\", \"makes\", \"for\", \"no\", \"work\", \"no\", \"fun\", \"and\", \"no\", \"results\"] then the second and third appearences of \"no\" is the closest pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def closest_repeated_entries(words):\n",
    "    #key is a word, value is (last_seen index, closest_distance)\n",
    "    visited_words = {}\n",
    "    for index, word in enumerate(words):\n",
    "        if word in visited_words:\n",
    "            last_seen_ix, closest_distance = visited_words[word]\n",
    "            #have only seen the word once so far\n",
    "            if closest_distance is None:\n",
    "                visited_words[word] = [index, (index - last_seen_ix)]\n",
    "            else:\n",
    "                if (index - last_seen_ix) < closest_distance:\n",
    "                    visited_words[word] = [index, (index - last_seen_ix)]\n",
    "                else:\n",
    "                    #another occurence seen, but it is not the closest pair\n",
    "                    #so just update the last_seen_index\n",
    "                    visited_words[word][0] = index\n",
    "        else:\n",
    "            visited_words[word] = [index, None]\n",
    "            \n",
    "    return min(visited_words.items(), key=lambda t: t[1][1] if t[1][1] else math.inf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#slightly refactored\n",
    "def closest_repeated_entries(words):\n",
    "    words_to_nearest_index = {}\n",
    "    closest_word = [math.inf, None]\n",
    "    for index, word in enumerate(words):\n",
    "        if word in words_to_nearest_index:\n",
    "            #decide if the curr word  ix - last_seen_ix is the new closest\n",
    "            last_seen_ix = words_to_nearest_index[word]\n",
    "            closest_word = min(closest_word, [(index - last_seen_ix), word])\n",
    "        words_to_nearest_index[word] = index\n",
    "    return closest_word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('no', None)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(closest_repeated_entries([\"All\", \"work\", \"and\", \"no\", \"play\", \"makes\", \"for\",\n",
    "                          \"no\", \"work\", \"no\", \"fun\", \"and\", \"no\", \"results\"]),\n",
    " closest_repeated_entries([\"all\", \"work\", \"and\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.8 - Find The Smallest Subarray Containing All Values\n",
    "Write a program that takes an array of stringd and a set of strings, and return the indices of the starting and ending index of a shortest subarray of the given array that covers the set, i.e., constains all strings in the set.\n",
    "\n",
    "go through the array of words, get indices of every occurence of each word in the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "def smallest_subarray(words, keywords):\n",
    "    distance = math.inf\n",
    "    keywords_to_index = {}\n",
    "    #will be in form of (begin_ix, end_ix)\n",
    "    ret = (None, None)\n",
    "    #coerce keywords to set to improve efficiency of 'in'\n",
    "    for index, word in enumerate(words):\n",
    "        if word in keywords:\n",
    "            keywords_to_index[word] = index\n",
    "            if len(keywords_to_index) == len(keywords):\n",
    "                #need to calculate the distance between all keywords\n",
    "                begin_ix = min(keywords_to_index.values())\n",
    "                end_ix = max(keywords_to_index.values())\n",
    "                #if the new distance is smallest, update ret\n",
    "                if (end_ix - begin_ix) < distance:\n",
    "                    ret = (begin_ix, end_ix)\n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def smallest_subarray_oc(words, keywords):\n",
    "    distance = math.inf\n",
    "    keyword_to_index = OrderedDict()\n",
    "    #want keywords to be set, to improve efficiency of `in`\n",
    "    if not isinstance(keywords, set):\n",
    "        keywords = set(keywords)\n",
    "    ret = (None, None)\n",
    "    for index, word in enumerate(words):\n",
    "        if word in keywords:\n",
    "            keyword_to_index[word] = index\n",
    "            if len(keyword_to_index) == len(keywords):\n",
    "                start_ix = keyword_to_index.popitem(last=False)[1]\n",
    "                end_ix = keyword_to_index[word]\n",
    "                if (end_ix - start_ix) < distance:\n",
    "                    ret = (start_ix, end_ix)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9, 12), (8, 10))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(smallest_subarray(['a', 'z', 'b', 'z', 'z', 'c', 'z', 'z', 'z', 'c',  'z', 'a', 'b'], ['a', 'b', 'c']),\n",
    " smallest_subarray(['apple', 'banana', 'apple', 'apple', 'dog', 'cat', 'apple', 'dog',\n",
    "                    'banana', 'apple', 'cat', 'dog'], ['banana', 'cat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9, 12), (8, 10))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(smallest_subarray_oc(['a', 'z', 'b', 'z', 'z', 'c', 'z', 'z', 'z', 'c',  'z', 'a', 'b'], ['a', 'b', 'c']),\n",
    " smallest_subarray_oc(['apple', 'banana', 'apple', 'apple', 'dog', 'cat', 'apple', 'dog',\n",
    "                    'banana', 'apple', 'cat', 'dog'], ['banana', 'cat']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
